<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ananye Agarwal</title>
  
  <meta name="author" content="Ananye Agarwal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-VM50KQ62S3"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-VM50KQ62S3');
  </script>
</head>

<body>
  <section class="section">
    <div class="container px-4 py-5">
      <div class="columns is-centered">
        <div class="row">
          <div class="col-md-4 col-sm-6" align="center">
            <a href="images/Ananye_rect_jun_2022.jpg"><img style="width:80%;border-radius:10px;" alt="profile photo" src="images/Ananye_rect_jun_2022_min.jpg" class="hoverZoomLink"></a>
            <p style="text-align:center" class="py-3">
              <a href="mailto:ananyea@andrew.cmu.edu">Email</a> &nbsp|&nbsp
              <a href="https://twitter.com/anag004">Twitter</a> &nbsp|&nbsp
              <a href="https://github.com/anag004/">Github</a>
            </p>
          </div>
          <div class="col-md-8 col-sm-6">
            <p style="text-align:center">
              <name>Ananye Agarwal</name>
              <br><br>
              <b>Email: </b>ananyea [at] andrew [dot] cmu [dot] edu
            </p>
            <p>I am a PhD student at Carnegie Mellon University working with <a href="https://www.cs.cmu.edu/~dpathak/">Deepak Pathak</a>. I am interested in understanding how humans and animals carry out diverse tasks in many environments and how we can teach robots to do the same. 
            </p>
            <p>
              I graduated from <a href="https://home.iitd.ac.in/">IIT Delhi</a> with a B.Tech. in Computer Science and a President's Gold Medal. In the past, I have been lucky to work with <a href="https://www.cse.iitd.ac.in/~mausam/">Prof. Mausam</a> on neuro-symbolic AI and with <a rel="nofollow" href"http://manikvarma.org/">Prof. Manik Varma</a> on <a href="http://manikvarma.org/downloads/XC/XMLRepository.html">Extreme Classification</a>. I have also had the good fortune of interning at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-india/">Microsoft Research India</a> where I worked with <a href="https://ankit-garg-6.github.io/">Dr. Ankit Garg</a> on algebraic complexity. 
            </p>
          </div>
        </div>
      </div>
    </div>
  <section class="section">
    <div class="container">
      <div class="columns is-centered">
        <h2 class="title is-3" style="text-align: center; "> Publications </h2>
        <br>
        <div class="row no-gutters py-2">
          <div class="col-md-5 col-sm-6 mx-auto">
            <video playsinline autoplay loop muted src="images/spin-table-cleanup.mp4" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
          </div>
          <div class="hidden-lg hidden-md hidden-sm">&nbsp;</div>
          <div class="col-md-6 col-sm-6 mx-auto">
            <a href="https://spin-robot.github.io/"><papertitle>SPIN: Simultaneous Perception, Interaction and Navigation</papertitle></a>
            <p>Shagun Uppal, <b>Ananye Agarwal</b>, Haoyu Xiong, Kenneth Shaw, Deepak Pathak</p>
            <p style="color: #c50202"><b>CVPR 2024</b></p>
            <a href="https://spin-robot.github.io/">webpage</a> |
            <a href="https://arxiv.org/abs/2405.07991">arXiv</a> 
          </div>
        </div>
        <div class="row no-gutters py-2">
          <div class="col-md-5 col-sm-6 mx-auto">
            <img src='images/sapg-schematic.jpg' alt="sym" width="80%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;">
          </div>
          <div class="hidden-lg hidden-md hidden-sm">&nbsp;</div>
          <div class="col-md-6 col-sm-6 mx-auto">
            <a href="ttps://sapg-rl.github.io/"><papertitle>SAPG: Split and Aggregate Policy Gradients</papertitle></a>
            <p>Jayesh Singla*, <b>Ananye Agarwal*</b>, Deepak Pathak</p>
            <p style="color: #c50202"><b>ICML 2024 (Oral)</b></p>
            <a href="https://sapg-rl.github.io/">webpage</a>  
          </div>
        </div>
        <div class="row no-gutters py-2">
          <div class="col-md-5 col-sm-6 mx-auto">
            <video playsinline autoplay loop muted src="https://dexfunc.github.io/resources/dexfunc-website-video.mp4" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
          </div>
          <div class="hidden-lg hidden-md hidden-sm">&nbsp;</div>
          <div class="col-md-6 col-sm-6 mx-auto">
            <a href="https://dexfunc.github.io/"><papertitle>Dexterous Functional Grasping</papertitle></a>
            <p><b>Ananye Agarwal</b>, Shagun Uppal, Kenneth Shaw, Deepak Pathak</p>
            <p style="color: #c50202"><b>CoRL 2023</b></p>
            <a href="https://dexfunc.github.io/">webpage</a> |
            <a href="https://arxiv.org/abs/2312.02975">arXiv</a> 
          </div>
        </div>
        <div class="row no-gutters py-2">
          <div class="col-md-5 col-sm-6 mx-auto">
            <video playsinline autoplay loop muted src="images/parkour.mp4" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
          </div>
          <div class="hidden-lg hidden-md hidden-sm">&nbsp;</div>
          <div class="col-md-6 col-sm-6 mx-auto">
            <a href="https://extreme-parkour.github.io/"><papertitle>Extreme Parkour with Legged Robots</papertitle></a>
            <p>Xuxin Cheng*, Kexin Shi*, <b>Ananye Agarwal</b>, Deepak Pathak</p>
            <p style="color: #c50202"><b>arXiv 2023</b></p>
            <a href="https://extreme-parkour.github.io/">webpage</a> |
            <a href="https://arxiv.org/abs/2309.14341">arXiv</a> |
            <a href="https://github.com/chengxuxin/extreme-parkour">code</a>
          </div>
        </div>
          <div class="row no-gutters py-2">
            <div class="col-md-5 col-sm-6 mx-auto">
              <video playsinline autoplay loop muted src="images/leap_sim2real.mp4" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
            </div>
            <div class="hidden-lg hidden-md hidden-sm">&nbsp;</div>
            <div class="col-md-6 col-sm-6 mx-auto">
              <a href="http://leaphand.com/"><papertitle>LEAP Hand: Low-Cost, Efficient, and Anthropomorphic Hand for Robot Learning</papertitle></a>
              <p>Kenneth Shaw, <b>Ananye Agarwal</b>, Deepak Pathak </p>
              <p style="color: #c50202"><b>RSS 2023</b></p>
              <a href="https://leap-hand.github.io/">webpage</a> |
              <a href="https://rss2023.github.io/rss2023-website/program/papers/089/">paper</a>
            </div>
        <div class="row no-gutters py-2">
          <div class="col-md-5 col-sm-6 mx-auto">
            <video playsinline autoplay loop muted src="images/vision-loco-clip.mp4" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
          </div>
          <div class="hidden-lg hidden-md hidden-sm">&nbsp;</div>
          <div class="col-md-6 col-sm-6 mx-auto">
            <a href="https://vision-locomotion.github.io/"><papertitle>Legged Locomotion in Challenging Terrains using Egocentric Vision</papertitle></a>
            <p><b>Ananye Agarwal*</b>, Ashish Kumar*, Jitendra Malik<sup>&#8224;</sup>, Deepak Pathak<sup>&#8224;</sup></p>
            <p style="color: #c50202"><b>CoRL 2022 (Best Systems Paper Award)</b></p>
            <a href="https://vision-locomotion.github.io/">webpage</a> |
            <a href="https://arxiv.org/abs/2211.07638">arXiv</a> |
            <a href="https://youtu.be/5sRqythe6TE">demo</a> |
            <a href="https://vision-locomotion.github.io#press-coverage">in the media</a>
          </div>
        <div class="row no-gutters py-2">
          <div class="col-md-5 col-sm-6 mx-auto">
            <video playsinline autoplay loop muted src="images/nav-clip.mp4" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
          </div>
          <div class="hidden-lg hidden-md hidden-sm">&nbsp;</div>
          <div class="col-md-6 col-sm-6 mx-auto">
            <a href="https://navigation-locomotion.github.io/camera-ready/"><papertitle>Coupling Vision and Proprioception for Navigation of Legged Robots</papertitle></a>
            <p>Zipeng Fu*, Ashish Kumar*, <b>Ananye Agarwal</b>, Haozhi Qi, Jitendra Malik, Deepak Pathak</p>
            <p style="color: #c50202"><b>CVPR 2022 (Best Paper at Multimodal Learning Workshop)</b></p>
            <a href="https://navigation-locomotion.github.io/camera-ready/">webpage</a> |
            <a href="https://arxiv.org/pdf/2112.02094.pdf">pdf</a> |
            <a href="https://arxiv.org/abs/2112.02094">arXiv</a> |
            <a href="https://github.com/MarkFzp/navigation-locomotion">code</a> |
            <a href="https://www.youtube.com/watch?v=sZVvutQUAQ4">video</a>
          </div>
        </div>
      </div>
      <div class="row no-gutters py-2 mx-auto">
        <div class="col-md-5 col-sm-6 mx-auto">
          <img src='images/nsnnet.jpg' alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;">
        </div>
        <div class="hidden-lg hidden-md hidden-sm">&nbsp;</div>
        <div class="col-md-6 col-sm-6 mx-auto">
          <a href="https://navigation-locomotion.github.io/camera-ready/"><papertitle>End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks</papertitle></a>
          <p><b>Ananye Agarwal</b>, Pradeep Shenoy, Mausam </p>
          <p><a href="https://arxiv.org/abs/2106.03121">arXiv</a></p>
        </div>
      </div>
      <div class="row no-gutters py-2">
        <div class="col-md-5 col-sm-6 mx-auto">
          <img src='images/siamesexml.jpg' alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;">
        </div>
        <div class="hidden-lg hidden-md hidden-sm">&nbsp;</div>
        <div class="col-md-6 col-sm-6 mx-auto">
          <a href="https://navigation-locomotion.github.io/camera-ready/"><papertitle>SiameseXML: Siamese networks meet extreme classifiers with 100M labels</papertitle></a>
          <p>K. Dahiya, <b>A. Agarwal</b>, D. Saini, K. Gururaj, J. Jiao, A. Singh, S. Agarwal, P. Kar and M. Varma</p>
          <p>ICML 2021</p>
          <a href="http://manikvarma.org/pubs/dahiya21b.pdf">PDF</a> | <a href="https://github.com/Extreme-classification/siamesexml">code</a>
        </div>
      </div>
    </div>
  </section>
  <section class="section py-5">
    <div class="container">
      <div class="row justify-content-center">
        <div class="col-12 text-center">
          <h2 class="title">Live Demos</h2>
        </div>
        <div class="col-12">
          <p>
            Our small low-cost robot can perceive and traverse challenging terrain. This uses a single neural network running onboard that directly maps pixels to joint torques.
          </p>
        </div>
      </div>
      <div class="row">
        <div class="col-md-6 mb-4">
          <video class="w-100 rounded" playsinline autoplay loop muted src="images/corl-demo-1.mp4" alt="Demo 1"></video>
        </div>
        <div class="col-md-6 mb-4">
          <video class="w-100 rounded" playsinline autoplay loop muted src="images/corl-demo-2.mp4" alt="Demo 2"></video>
        </div>
      </div>
      <div class="row">
        <div class="col-12 text-center mb-4">
          <figcaption>CoRL 2021, Auckland</figcaption>
        </div>
      </div>
      <div class="row">
        <div class="col-md-6 mb-4">
          <video class="w-100 rounded" playsinline autoplay loop muted src="images/cvpr-demo1.mp4" alt="Demo 3"></video>
        </div>
        <div class="col-md-6 mb-4">
          <video class="w-100 rounded" playsinline autoplay loop muted src="images/cvpr-demo2.mp4" alt="Demo 4"></video>
        </div>
      </div>
      <div class="row">
        <div class="col-12 text-center">
          <figcaption>CVPR 2021, New Orleans</figcaption>
        </div>
      </div>
    </div>
    </div>
  </section>
  <section class="section">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12">
                <h2 class="text-center mb-3">Press Coverage</h2>
                <div class="row justify-content-center">
                    <div class="col">
                        <a target="_blank" href="https://www.technologyreview.com/2022/11/21/1063585/watch-this-robot-dog-scramble-over-tricky-terrain-just-by-using-its-camera/">
                            <img src="images/logos/mit-tech-review.jpg" class="img-fluid" alt="MIT Tech Review">
                        </a>
                    </div>
                    <div class="col">
                        <a target="_blank" href="https://techcrunch.com/2022/11/16/this-robotic-dog-can-walk-over-just-about-any-terrain/">
                            <img src="images/logos/tech-crunch.jpg" class="img-fluid" alt="TechCrunch">
                        </a>
                    </div>
                    <div class="col">
                        <a target="_blank" href="https://www.techeblog.com/cmu-robot-dog-climb-stairs/">
                            <img src="images/logos/tech-e-blog.jpg" class="img-fluid" alt="Tech E Blog">
                        </a>
                    </div>
                    <div class="col">
                        <a target="_blank" href="https://www.unite.ai/low-cost-robot-navigates-nearly-any-obstacle/">
                            <img src="images/logos/unite-ai.jpg" class="img-fluid" alt="Unite AI">
                        </a>
                    </div>
                </div>
                <br>
                <div class="row justify-content-center">
                    <div class="col">
                        <a target="_blank" href="https://spectrum.ieee.org/video-friday-little-robot-big-stairs">
                            <img src="images/logos/ieee-spectrum.jpg" class="img-fluid" alt="IEEE Spectrum">
                        </a>
                    </div>
                    <div class="col">
                        <a target="_blank" href="https://cosmosmagazine.com/science/honeybee-lifespan-climbing-robot/">
                            <img src="images/logos/cosmos.png" class="img-fluid" alt="Cosmos Magazine">
                        </a>
                    </div>
                    <div class="col">
                        <a target="_blank" href="https://technologymagazine.com/articles/budget-robots-inspired-by-animals-a-step-forward-for-humans">
                            <img src="images/logos/technology.jpg" class="img-fluid" alt="Technology Magazine">
                        </a>
                    </div>
                    <div class="col">
                        <a target="_blank" href="https://www.techcircle.in/2022/11/21/researchers-build-a-four-legged-robot-that-can-climb-stairs-hills">
                            <img src="images/logos/tech-circle.jpg" class="img-fluid" alt="Tech Circle">
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

  
  <!-- <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="height: 200px">
                <img src='images/nsnnet.jpg' width="320">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>End-to-End Neuro-Symbolic Architecture for Image-to-Image Reasoning Tasks</papertitle>
              <p></p>
							<b>Ananye Agarwal</b>, Pradeep Shenoy, Mausam 
              <br>
              arXiv 2021 
              <br>
              <a href="https://arxiv.org/abs/2106.03121">arXiv</a>
              <p></p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="height: 200px">
                <img src='images/siamesexml.jpg' width="320">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>SiameseXML: Siamese networks meet extreme classifiers with 100M labels</papertitle>
              <p></p>
							K. Dahiya, <b>A. Agarwal</b>, D. Saini, K. Gururaj, J. Jiao, A. Singh, S. Agarwal, P. Kar and M. Varma
              <br>
              ICML 2021
              <br>
              <a href="http://manikvarma.org/pubs/dahiya21b.pdf">PDF</a> | <a href="https://github.com/Extreme-classification/siamesexml">code</a>
              <p></p>
            </td>
          </tr> 
          <tr><td></td><td style="font-size: 14px;">Website template modified from <a href="https://github.com/jonbarron/website" style="font-size: 14px;">Jon Barron's repo</a>. </td></tr>
        </tbody></table> -->
        
</body>

</html>
